{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NkBHAHbAiTwC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import pickle\n",
        "import numpy as np\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "A0w5yuR-ir0W"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "file_path = \"/content/franklin.txt\"  # Adjust the path according to your dataset\n",
        "with open(file_path, \"r\", encoding=\"utf8\") as file:\n",
        "    lines = file.readlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ibu2BEgjizwb"
      },
      "outputs": [],
      "source": [
        "# Preprocess text\n",
        "data = ' '.join([line.strip() for line in lines])\n",
        "data = data.replace('\\n', ' ').replace('\\r', ' ').replace('\\ufeff', '').replace('“', '').replace('”', '')\n",
        "data = ' '.join(data.split())  # Remove multiple spaces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Om5qlcYZi5dK"
      },
      "outputs": [],
      "source": [
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts([data])\n",
        "\n",
        "# Save tokenizer\n",
        "with open(\"tokenizer.pkl\", \"wb\") as token_file:\n",
        "    pickle.dump(tokenizer, token_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNe0VsEOi9Uf",
        "outputId": "4ae6601f-7860-4a09-99a9-72cd3a1d10c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary Size: 8307\n"
          ]
        }
      ],
      "source": [
        "# Convert text to sequences\n",
        "sequence_data = tokenizer.texts_to_sequences([data])[0]\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocabulary Size:\", vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "2MrTr9t0jClR"
      },
      "outputs": [],
      "source": [
        "# Prepare input sequences\n",
        "sequences = []\n",
        "for i in range(3, len(sequence_data)):\n",
        "    words = sequence_data[i-3:i+1]\n",
        "    sequences.append(words)\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X, y = sequences[:, :-1], sequences[:, -1]\n",
        "y = to_categorical(y, num_classes=vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnXx2m9DjGme",
        "outputId": "d1619176-0b29-4776-fc90-9a2f75e50530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Define the model\n",
        "model = Sequential([\n",
        "    Embedding(vocab_size, 10, input_length=3),\n",
        "    LSTM(1000, return_sequences=True),\n",
        "    LSTM(1000),\n",
        "    Dense(1000, activation=\"relu\"),\n",
        "    Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", metrics=['accuracy'], optimizer=Adam(learning_rate=0.001))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmXLGqrFjNHo",
        "outputId": "67dc7b98-fb09-4df5-99bb-d071c7f1a231"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.0511 - loss: 7.0029\n",
            "Epoch 2/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.0868 - loss: 6.2570\n",
            "Epoch 3/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 25ms/step - accuracy: 0.1065 - loss: 5.8937\n",
            "Epoch 4/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.1206 - loss: 5.6202\n",
            "Epoch 5/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.1347 - loss: 5.3543\n",
            "Epoch 6/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.1441 - loss: 5.1306\n",
            "Epoch 7/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.1525 - loss: 4.9008\n",
            "Epoch 8/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.1619 - loss: 4.6374\n",
            "Epoch 9/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.1767 - loss: 4.3509\n",
            "Epoch 10/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.1988 - loss: 4.0379\n",
            "Epoch 11/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.2255 - loss: 3.7620\n",
            "Epoch 12/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - accuracy: 0.2656 - loss: 3.4413\n",
            "Epoch 13/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.3023 - loss: 3.1856\n",
            "Epoch 14/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.3388 - loss: 2.9344\n",
            "Epoch 15/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - accuracy: 0.3800 - loss: 2.6856\n",
            "Epoch 16/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - accuracy: 0.4188 - loss: 2.4569\n",
            "Epoch 17/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.4611 - loss: 2.2398\n",
            "Epoch 18/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.5054 - loss: 2.0117\n",
            "Epoch 19/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.5452 - loss: 1.8212\n",
            "Epoch 20/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - accuracy: 0.5862 - loss: 1.6238\n",
            "Epoch 21/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.6328 - loss: 1.4248\n",
            "Epoch 22/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - accuracy: 0.6667 - loss: 1.2670\n",
            "Epoch 23/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.7048 - loss: 1.1174\n",
            "Epoch 24/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.7434 - loss: 0.9730\n",
            "Epoch 25/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.7732 - loss: 0.8618\n",
            "Epoch 26/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.7953 - loss: 0.7736\n",
            "Epoch 27/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8165 - loss: 0.7032\n",
            "Epoch 28/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8316 - loss: 0.6327\n",
            "Epoch 29/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8463 - loss: 0.5856\n",
            "Epoch 30/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8564 - loss: 0.5455\n",
            "Epoch 31/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8664 - loss: 0.5010\n",
            "Epoch 32/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.8669 - loss: 0.4816\n",
            "Epoch 33/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8776 - loss: 0.4492\n",
            "Epoch 34/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.8796 - loss: 0.4378\n",
            "Epoch 35/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.8835 - loss: 0.4212\n",
            "Epoch 36/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.8821 - loss: 0.4133\n",
            "Epoch 37/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8866 - loss: 0.3967\n",
            "Epoch 38/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.8916 - loss: 0.3724\n",
            "Epoch 39/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8898 - loss: 0.3699\n",
            "Epoch 40/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.8911 - loss: 0.3613\n",
            "Epoch 41/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8962 - loss: 0.3456\n",
            "Epoch 42/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8964 - loss: 0.3391\n",
            "Epoch 43/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.8932 - loss: 0.3415\n",
            "Epoch 44/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.8965 - loss: 0.3267\n",
            "Epoch 45/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.8979 - loss: 0.3231\n",
            "Epoch 46/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8984 - loss: 0.3134\n",
            "Epoch 47/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 26ms/step - accuracy: 0.9003 - loss: 0.3061\n",
            "Epoch 48/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9012 - loss: 0.3004\n",
            "Epoch 49/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8987 - loss: 0.3021\n",
            "Epoch 50/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.8969 - loss: 0.3030\n",
            "Epoch 51/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9000 - loss: 0.2942\n",
            "Epoch 52/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.8964 - loss: 0.2977\n",
            "Epoch 53/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.9000 - loss: 0.2871\n",
            "Epoch 54/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.8991 - loss: 0.2888\n",
            "Epoch 55/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9023 - loss: 0.2787\n",
            "Epoch 56/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9001 - loss: 0.2813\n",
            "Epoch 57/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9038 - loss: 0.2685\n",
            "Epoch 58/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9012 - loss: 0.2701\n",
            "Epoch 59/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 25ms/step - accuracy: 0.9022 - loss: 0.2659\n",
            "Epoch 60/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9024 - loss: 0.2638\n",
            "Epoch 61/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 26ms/step - accuracy: 0.9012 - loss: 0.2620\n",
            "Epoch 62/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9023 - loss: 0.2580\n",
            "Epoch 63/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9024 - loss: 0.2546\n",
            "Epoch 64/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.8986 - loss: 0.2628\n",
            "Epoch 65/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9022 - loss: 0.2533\n",
            "Epoch 66/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9030 - loss: 0.2508\n",
            "Epoch 67/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.9020 - loss: 0.2522\n",
            "Epoch 68/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 25ms/step - accuracy: 0.9016 - loss: 0.2503\n",
            "Epoch 69/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9028 - loss: 0.2452\n",
            "Epoch 70/70\n",
            "\u001b[1m1247/1247\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 26ms/step - accuracy: 0.9033 - loss: 0.2407\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b292955d050>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=70, batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4AsF5RU3nvpL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6be6a34f-1287-44b0-9041-4c71e4661b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Save model\n",
        "model.save(\"text_prediction_model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Q4IKCGfpnw1l"
      },
      "outputs": [],
      "source": [
        "# Load model and tokenizer\n",
        "def load_model_and_tokenizer():\n",
        "    model = load_model(\"text_prediction_model.h5\")\n",
        "    with open(\"tokenizer.pkl\", \"rb\") as token_file:\n",
        "        tokenizer = pickle.load(token_file)\n",
        "    return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "iWtN_OVJn1xg"
      },
      "outputs": [],
      "source": [
        "# Predict function\n",
        "def predict_next_word(seed_text, model, tokenizer, num_words=1):\n",
        "    for _ in range(num_words):\n",
        "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
        "        token_list = np.array(token_list[-3:]).reshape(1, -1)\n",
        "        predicted_probs = model.predict(token_list, verbose=0)\n",
        "        predicted_index = np.argmax(predicted_probs)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        seed_text += \" \" + output_word\n",
        "    return seed_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9cMxXt75n5kh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78bed65-3d28-427a-e00a-15a00f8f7e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the power of credit and all finding his\n"
          ]
        }
      ],
      "source": [
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "    seed_text = \"the power of\"\n",
        "    print(predict_next_word(seed_text, model, tokenizer, num_words=5))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    model, tokenizer = load_model_and_tokenizer()\n",
        "    seed_text = \"When I saw one\"\n",
        "    print(predict_next_word(seed_text, model, tokenizer, num_words=5))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xjf-NHOLdXR",
        "outputId": "69f5ce63-0deb-44d7-c207-bc86ebc22ddf"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "When I saw one too ambitious of court favor\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}